{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fce8430-32c9-407d-ade2-8396914b9cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "957a664e-5cb6-420b-8009-ef3b3a445a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdReLU(nn.Module):\n",
    "    def __init__(self, threshold=0.001):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "    def forward(self, x):\n",
    "        return torch.where(x > self.threshold, x, torch.zeros_like(x))\n",
    "\n",
    "def quantize_input(x, levels=16, lo=0.0, hi=1.0):\n",
    "    x = x.clamp(lo, hi)\n",
    "    x_norm = (x - lo) / (hi - lo)\n",
    "    x_q = torch.round(x_norm * (levels - 1)) / (levels - 1)\n",
    "    return x_q * (hi - lo) + lo\n",
    "\n",
    "def sparsity_loss_modified(acts, beta=20.0):\n",
    "    total = sum(a.numel() for a in acts)\n",
    "    loss = 0.0\n",
    "    for a in acts:\n",
    "        loss += torch.sum(1.0 - torch.tanh(beta * a.abs()))\n",
    "    return loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621c2aeb-4223-4799-adb7-42471f7305a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet_Sparse(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # use torchvision’s AlexNet features\n",
    "        self.features   = torchvision.models.alexnet(pretrained=False).features\n",
    "        # adapt pooling to 1×1\n",
    "        self.pool       = nn.AdaptiveAvgPool2d((1,1))\n",
    "        # classifier head for CIFAR‑10\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256*1*1, 4096),\n",
    "            ThresholdReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            ThresholdReLU(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        acts = []\n",
    "        for layer in self.features:\n",
    "            x = layer(x)\n",
    "            # record activations right after each BatchNorm or ReLU\n",
    "            if isinstance(layer, (nn.BatchNorm2d, nn.ReLU)):\n",
    "                acts.append(x.clone())\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18789d05-5727-43da-b3bb-9354f504a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sparsity_adversary(model, x_clean, y_clean, criterion,\n",
    "                                epsilon=0.5, alpha=0.05, num_iter=120,\n",
    "                                c=0.0, beta=50.0):\n",
    "    model.eval()\n",
    "    x_adv = x_clean.detach().clone().to(device)\n",
    "    x_adv.requires_grad = True\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        logits, acts = model(x_adv)\n",
    "        l_sp = sparsity_loss_modified(acts, beta=beta)\n",
    "        loss = l_sp  # c=0 means ignore CE\n",
    "        model.zero_grad(); loss.backward()\n",
    "        x_adv = x_adv - alpha * x_adv.grad.sign()\n",
    "        # project back into L∞(ε) around x_clean\n",
    "        x_adv = torch.max(torch.min(x_adv, x_clean+epsilon),\n",
    "                          x_clean-epsilon).clamp(0.0,1.0)\n",
    "        x_adv = x_adv.detach(); x_adv.requires_grad = True\n",
    "\n",
    "        if (i+1) % 30 == 0:\n",
    "            print(f\"WB iter {i+1}/{num_iter}, SP loss: {l_sp.item():.4f}\")\n",
    "\n",
    "    return x_adv.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c87a69a-1e33-4202-9c96-95010d7cde0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPSAAttack:\n",
    "    def __init__(self, model, bounds=(0,1), sigma=2e-3, lr=1e-2,\n",
    "                 max_iter=500, targeted=True, samples=4):\n",
    "        \"\"\"\n",
    "        Black‑box SPSA repair attack:\n",
    "        - model:        the target (black‑box) model\n",
    "        - bounds:       pixel range to clip to (lo, hi)\n",
    "        - sigma:        finite‑difference probe size\n",
    "        - lr:           step size for estimated gradient descent\n",
    "        - max_iter:     number of SPSA iterations\n",
    "        - targeted:     if True, pulls toward tgt_label; else pushes away\n",
    "        - samples:      number of random finite‑difference samples per step\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model    = model\n",
    "        self.lo, self.hi = bounds\n",
    "        self.sigma    = sigma\n",
    "        self.lr       = lr\n",
    "        self.max_iter = max_iter\n",
    "        self.targeted = targeted\n",
    "        self.samples  = samples\n",
    "\n",
    "    def attack(self, x_orig, tgt_label):\n",
    "        # 1) Setup: start with zero perturbation \n",
    "        device = x_orig.device\n",
    "        delta  = torch.zeros_like(x_orig, device=device)\n",
    "        tgt    = torch.tensor([tgt_label], device=device)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # 2) Estimate gradient via SPSA:\n",
    "            grad_est = torch.zeros_like(delta)\n",
    "            for _ in range(self.samples):\n",
    "                #  Sample random + or - 1 vector \n",
    "                u = torch.randint(0,2,x_orig.shape,device=device).float()*2 - 1\n",
    "                # Evaluate model \n",
    "                x_p = torch.clamp(x_orig+delta+self.sigma*u, self.lo, self.hi)\n",
    "                x_n = torch.clamp(x_orig+delta-self.sigma*u, self.lo, self.hi)\n",
    "                lp,_ = self.model(x_p); ln,_ = self.model(x_n)\n",
    "                # Compute loss difference (targeted or untargeted)\n",
    "                l_p = F.cross_entropy(lp, tgt)\n",
    "                l_n = F.cross_entropy(ln, tgt)\n",
    "                diff = (l_p - l_n) if self.targeted else (l_n - l_p)\n",
    "                #Accumulate gradient estimate\n",
    "                grad_est += diff * u / (2*self.sigma)\n",
    "\n",
    "            #Average over samples\n",
    "            grad_est /= self.samples\n",
    "            # 3) Step against the estimated gradient\n",
    "            delta = delta - self.lr * grad_est\n",
    "            # 4) Project Delta back into valid ball around x_orig\n",
    "            delta = torch.clamp(delta, self.lo - x_orig, self.hi - x_orig)\n",
    "        #Return the repaired adversarial: x_orig + delta clipped to image range\n",
    "        return torch.clamp(x_orig + delta, self.lo, self.hi).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72cb2d4b-67c6-4622-965f-ac2e466e1a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rushik/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/rushik/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std  = (0.2023, 0.1994, 0.2010)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),              # AlexNet expects larger input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "testset  = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# ─── 7) Instantiate & Load ────────────────────────────────\n",
    "model     = AlexNet_Sparse().to(device)\n",
    "model.eval()\n",
    "surrogate = model\n",
    "target    = copy.deepcopy(model)\n",
    "surrogate.eval(); target.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "spsa = SPSAAttack(model=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b369d4-8536-4963-a7e8-b7fe735d232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WB iter 30/120, SP loss: 0.4564\n",
      "WB iter 60/120, SP loss: 0.4437\n",
      "WB iter 90/120, SP loss: 0.4385\n",
      "WB iter 120/120, SP loss: 0.4353\n",
      "Sparsity clean: 0.5027, adversarial: 0.6014\n"
     ]
    }
   ],
   "source": [
    "for imgs, _ in testloader:\n",
    "    imgs = imgs.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits_c, acts_c = target(quantize_input(imgs))\n",
    "        preds_c = logits_c.argmax(1)\n",
    "\n",
    "    imgs_q  = quantize_input(imgs)\n",
    "    imgs_s1 = generate_sparsity_adversary(\n",
    "                   surrogate, imgs_q, preds_c, criterion,\n",
    "                   epsilon=0.5, alpha=0.05, num_iter=120,\n",
    "                   c=0.0, beta=50.0\n",
    "               )\n",
    "\n",
    "    imgs_adv = imgs_s1.clone()\n",
    "    for i in range(imgs.size(0)):\n",
    "        with torch.no_grad():\n",
    "            pi = target(imgs_s1[i:i+1])[0].argmax(1)\n",
    "        if pi != preds_c[i]:\n",
    "            imgs_adv[i:i+1] = spsa.attack(imgs_s1[i:i+1], preds_c[i].item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, acts_a = target(quantize_input(imgs_adv))\n",
    "    sp_c = sum((a!=0).float().sum() for a in acts_c)/sum(a.numel() for a in acts_c)\n",
    "    sp_a = sum((a!=0).float().sum() for a in acts_a)/sum(a.numel() for a in acts_a)\n",
    "\n",
    "    print(f\"Sparsity clean: {sp_c:.4f}, adversarial: {sp_a:.4f}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5911a-eaf9-4fbd-9175-5ea41a083b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
