{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c0596e-af23-4831-9cf8-fe1183581b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78fcdae-f715-4cab-b638-d6fd3c27fe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --- Data ---\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f468ee3-5abe-4c53-a4ca-c29317cb53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower the threshold to reduce aggressive zeroing\n",
    "class ThresholdReLU(nn.Module):\n",
    "    def __init__(self, threshold=0.001):\n",
    "        super(ThresholdReLU, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.where(x > self.threshold, x, torch.tensor(0.0, device=x.device))\n",
    "\n",
    "# Quantize normalized inputs (assuming they roughly lie in [-2.5, 2.5])\n",
    "def quantize_input(x, levels=16, min_val=-2.5, max_val=2.5):\n",
    "    x = torch.clamp(x, min_val, max_val)\n",
    "    x_norm = (x - min_val) / (max_val - min_val)   # map to [0,1]\n",
    "    x_quant = torch.round(x_norm * (levels - 1)) / (levels - 1)\n",
    "    x_new = x_quant * (max_val - min_val) + min_val\n",
    "    return x_new\n",
    "\n",
    "# Normalized sparsity loss (L1 norm divided by total number of elements)\n",
    "def sparsity_loss(activations, weight=1e-6):\n",
    "    total_elements = sum(act.numel() for act in activations)\n",
    "    loss = sum(torch.norm(act, 1) for act in activations)\n",
    "    return weight * loss / total_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38db2f2b-5d90-4cb6-824e-25a70a5107e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = ThresholdReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        out2 = self.bn2(self.conv2(out1))\n",
    "        out2 += self.shortcut(x)\n",
    "        out = self.relu(out2)\n",
    "        return out, out1  # out is the block's output, out1 is used for sparsity loss\n",
    "\n",
    "class ResNet20(nn.Module):\n",
    "    def __init__(self, block=BasicBlock, num_classes=10):\n",
    "        super(ResNet20, self).__init__()\n",
    "        self.in_channels = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = ThresholdReLU()\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 16, 3, stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, 3, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, 3, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride):\n",
    "        strides = [stride] + [1] * (blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, s))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        activations = []\n",
    "        for block in self.layer1:\n",
    "            out, act = block(out)\n",
    "            activations.append(act)\n",
    "        for block in self.layer2:\n",
    "            out, act = block(out)\n",
    "            activations.append(act)\n",
    "        for block in self.layer3:\n",
    "            out, act = block(out)\n",
    "            activations.append(act)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out, activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f13cd0-6c7b-4289-a634-f4c7de70dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Apply quantization on normalized inputs\n",
    "        images = quantize_input(images)\n",
    "\n",
    "        outputs, activations = model(images)\n",
    "        loss_main = criterion(outputs, labels)\n",
    "        loss_sparse = sparsity_loss(activations)\n",
    "        loss = loss_main + loss_sparse\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Optional: Log individual loss components for debugging\n",
    "        # print(f\"Loss_main: {loss_main.item()}, Loss_sparse: {loss_sparse.item()}\")\n",
    "\n",
    "    return running_loss / total, 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f834b7-db58-43a1-841b-06f34a951221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images = quantize_input(images)\n",
    "\n",
    "            outputs, activations = model(images)\n",
    "            loss_main = criterion(outputs, labels)\n",
    "            loss_sparse = sparsity_loss(activations)\n",
    "            loss = loss_main + loss_sparse\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return running_loss / total, 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06350e27-cf57-4664-8b5c-8128b6aeffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet20().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb50a121-66c6-49d2-abaf-0bdc88935d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "  Train Loss: 1.6968, Train Acc: 36.13%\n",
      "  Test  Loss: 1.5141, Test  Acc: 46.11%\n",
      "Epoch [2/10]\n",
      "  Train Loss: 1.2302, Train Acc: 55.35%\n",
      "  Test  Loss: 1.1916, Test  Acc: 59.40%\n",
      "Epoch [3/10]\n",
      "  Train Loss: 0.9685, Train Acc: 65.42%\n",
      "  Test  Loss: 0.9303, Test  Acc: 68.53%\n",
      "Epoch [4/10]\n",
      "  Train Loss: 0.8025, Train Acc: 71.90%\n",
      "  Test  Loss: 0.7628, Test  Acc: 73.78%\n",
      "Epoch [5/10]\n",
      "  Train Loss: 0.7091, Train Acc: 75.26%\n",
      "  Test  Loss: 1.0828, Test  Acc: 67.58%\n",
      "Epoch [6/10]\n",
      "  Train Loss: 0.6460, Train Acc: 77.68%\n",
      "  Test  Loss: 0.7052, Test  Acc: 76.09%\n",
      "Epoch [7/10]\n",
      "  Train Loss: 0.6007, Train Acc: 79.14%\n",
      "  Test  Loss: 0.8119, Test  Acc: 73.84%\n",
      "Epoch [8/10]\n",
      "  Train Loss: 0.5666, Train Acc: 80.44%\n",
      "  Test  Loss: 0.6509, Test  Acc: 78.51%\n",
      "Epoch [9/10]\n",
      "  Train Loss: 0.5319, Train Acc: 81.88%\n",
      "  Test  Loss: 0.6630, Test  Acc: 78.08%\n",
      "Epoch [10/10]\n",
      "  Train Loss: 0.5090, Train Acc: 82.38%\n",
      "  Test  Loss: 0.6169, Test  Acc: 79.18%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, trainloader, criterion, optimizer)\n",
    "    test_loss, test_acc = evaluate(model, testloader, criterion)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Test  Loss: {test_loss:.4f}, Test  Acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acb62524-7be2-47bc-a5cf-8a98e77be4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10/50, Loss: 0.1305, Loss_ce: 0.0008, Loss_sparse: 0.1296\n",
      "Iteration 20/50, Loss: 0.1215, Loss_ce: 0.0004, Loss_sparse: 0.1211\n",
      "Iteration 30/50, Loss: 0.1176, Loss_ce: 0.0004, Loss_sparse: 0.1172\n",
      "Iteration 40/50, Loss: 0.1156, Loss_ce: 0.0004, Loss_sparse: 0.1152\n",
      "Iteration 50/50, Loss: 0.1143, Loss_ce: 0.0004, Loss_sparse: 0.1139\n",
      "Clean Predictions:  tensor([3, 8, 8, 8, 6, 6, 1, 6, 3, 1], device='cuda:0')\n",
      "Adversarial Predictions:  tensor([3, 8, 8, 8, 6, 6, 1, 6, 3, 1], device='cuda:0')\n",
      "Sparsity (clean): 0.3928\n",
      "Sparsity (adv): 0.4202\n"
     ]
    }
   ],
   "source": [
    "def sparsity_loss_modified(activations, beta=10):\n",
    "    \"\"\"\n",
    "    Computes a loss that encourages activations to be above a certain value.\n",
    "    Here, we use a tanh-based approximation to count nonzero activations.\n",
    "    The function returns a negative value if activations are low,\n",
    "    thus encouraging them to increase.\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    total_elements = 0\n",
    "    for act in activations:\n",
    "        # tanh approximation: higher value means more likely to be nonzero.\n",
    "        # We subtract 0.5 to center around zero.\n",
    "        approx_nonzero = torch.tanh(beta * torch.abs(act)) - 0.5  \n",
    "        loss += -torch.sum(approx_nonzero)  # Negative to encourage nonzero activations.\n",
    "        total_elements += act.numel()\n",
    "    return loss / total_elements\n",
    "\n",
    "def generate_sparsity_adversary(model, x_clean, y_clean, criterion, epsilon=0.2, alpha=0.01, num_iter=50, c=1.0):\n",
    "    \"\"\"\n",
    "    Generates an adversarial example to reduce activation sparsity.\n",
    "    For gradient propagation, quantization is skipped in this version.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x_adv = x_clean.clone().detach().to(device)\n",
    "    x_adv.requires_grad = True\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        # Do not quantize here to allow clean gradients.\n",
    "        outputs, activations = model(x_adv)\n",
    "        loss_ce = criterion(outputs, y_clean)\n",
    "        loss_sparse = sparsity_loss_modified(activations, beta=10)\n",
    "        loss = loss_sparse + c * loss_ce\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        grad = x_adv.grad.data\n",
    "\n",
    "        x_adv = x_adv - alpha * grad.sign()\n",
    "\n",
    "        # Enforce L-inf bound on perturbation:\n",
    "        x_adv = torch.max(torch.min(x_adv, x_clean + epsilon), x_clean - epsilon)\n",
    "        # Clamp to valid range (assuming normalized values)\n",
    "        x_adv = torch.clamp(x_adv, -2.5, 2.5)\n",
    "\n",
    "        x_adv = x_adv.detach()\n",
    "        x_adv.requires_grad = True\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"Iteration {i+1}/{num_iter}, Loss: {loss.item():.4f}, Loss_ce: {loss_ce.item():.4f}, Loss_sparse: {loss_sparse.item():.4f}\")\n",
    "\n",
    "    return x_adv.detach()\n",
    "\n",
    "# Test the new adversarial attack on one batch (without quantization during attack)\n",
    "model.eval()\n",
    "for images, labels in testloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    # For adversarial generation, skip quantization to preserve gradient info.\n",
    "    outputs_clean, activations_clean = model(images)\n",
    "    _, preds_clean = outputs_clean.max(1)\n",
    "    \n",
    "    images_adv = generate_sparsity_adversary(model, images, preds_clean, criterion,\n",
    "                                             epsilon=0.2, alpha=0.01, num_iter=50, c=1.0)\n",
    "    \n",
    "    outputs_adv, activations_adv = model(images_adv)\n",
    "    _, preds_adv = outputs_adv.max(1)\n",
    "    \n",
    "    print(\"Clean Predictions: \", preds_clean[:10])\n",
    "    print(\"Adversarial Predictions: \", preds_adv[:10])\n",
    "    \n",
    "    def compute_sparsity(activations):\n",
    "        total_nonzero = sum((act != 0).float().sum().item() for act in activations)\n",
    "        total_elements = sum(act.numel() for act in activations)\n",
    "        return total_nonzero / total_elements\n",
    "\n",
    "    sparsity_clean = compute_sparsity(activations_clean)\n",
    "    sparsity_adv = compute_sparsity(activations_adv)\n",
    "    print(f\"Sparsity (clean): {sparsity_clean:.4f}\")\n",
    "    print(f\"Sparsity (adv): {sparsity_adv:.4f}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fee798-7d53-4133-b7cb-bc59883e8489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
