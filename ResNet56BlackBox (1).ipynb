{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "699c461c-f4d8-40fe-8cfe-08b456a3f4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# ─── Device ───\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6fdafd2-1a28-49fc-9ff2-934b890de370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdReLU(nn.Module):\n",
    "    def __init__(self, threshold=0.001):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "    def forward(self, x):\n",
    "        return torch.where(x > self.threshold, x, torch.zeros_like(x))\n",
    "\n",
    "def quantize_input(x, levels=16, lo=0.0, hi=1.0):\n",
    "    x = x.clamp(lo, hi)\n",
    "    x = (x - lo) / (hi - lo)\n",
    "    x = torch.round(x * (levels - 1)) / (levels - 1)\n",
    "    return x * (hi - lo) + lo\n",
    "\n",
    "def sparsity_loss_modified(activations, beta=20.0):\n",
    "    total = sum(a.numel() for a in activations)\n",
    "    loss = 0.0\n",
    "    for a in activations:\n",
    "        loss += torch.sum(1.0 - torch.tanh(beta * a.abs()))\n",
    "    return loss / total\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(out_ch)\n",
    "        self.act   = ThresholdReLU()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, 1, 1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_ch)\n",
    "        self.short = nn.Sequential()\n",
    "        if stride!=1 or in_ch!=out_ch:\n",
    "            self.short = nn.Sequential(\n",
    "                nn.Conv2d(in_ch,out_ch,1,stride,bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        y1 = self.act(self.bn1(self.conv1(x)))\n",
    "        y2 = self.bn2(self.conv2(y1)) + self.short(x)\n",
    "        out = self.act(y2)\n",
    "        return out, y1\n",
    "\n",
    "class ResNet56(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_ch = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(16)\n",
    "        self.act1  = ThresholdReLU()\n",
    "        self.layer1 = self._make_layer(16, 9, stride=1)\n",
    "        self.layer2 = self._make_layer(32, 9, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 9, stride=2)\n",
    "        self.avg   = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc    = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_ch, blocks, stride):\n",
    "        strides = [stride] + [1]*(blocks-1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(BasicBlock(self.in_ch, out_ch, s))\n",
    "            self.in_ch = out_ch\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.bn1(self.conv1(x)))\n",
    "        acts = []\n",
    "        for blk in self.layer1:\n",
    "            x, a = blk(x); acts.append(a)\n",
    "        for blk in self.layer2:\n",
    "            x, a = blk(x); acts.append(a)\n",
    "        for blk in self.layer3:\n",
    "            x, a = blk(x); acts.append(a)\n",
    "        x = self.avg(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x), acts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "789cfdc9-d806-432d-8c98-3550d84f2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sparsity_adversary(model, x_clean, y_clean, criterion,\n",
    "                                epsilon=0.2, alpha=0.01, num_iter=50,\n",
    "                                c=0.0, beta=20.0):\n",
    "    model.eval()\n",
    "    x_adv = x_clean.detach().clone().to(device)\n",
    "    x_adv.requires_grad = True\n",
    "    opt = optim.SGD([x_adv], lr=alpha, momentum=0.9)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        logits, acts = model(x_adv)\n",
    "        # use modified sparsity loss:\n",
    "        loss_sp = sparsity_loss_modified(acts, beta=beta)\n",
    "        loss_ce = criterion(logits, y_clean)\n",
    "        loss    = loss_sp + c*loss_ce\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # ascend on sparsity (c=0) or descend on CE if c>0\n",
    "        x_adv.data += alpha * x_adv.grad.sign()\n",
    "        # project back to L∞ ball\n",
    "        delta = torch.clamp(x_adv - x_clean, -epsilon, epsilon)\n",
    "        x_adv.data = torch.clamp(x_clean + delta, 0.0, 1.0)\n",
    "\n",
    "    return x_adv.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e68849d-03ff-484e-bb1d-b189f5eb3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPSAAttack:\n",
    "    def __init__(self, model, bounds=(0,1), sigma=1e-3, lr=1e-2,\n",
    "                 max_iter=200, targeted=True, samples=1):\n",
    "        self.model     = model\n",
    "        self.lo, self.hi = bounds\n",
    "        self.sigma     = sigma\n",
    "        self.lr        = lr\n",
    "        self.max_iter  = max_iter\n",
    "        self.targeted  = targeted\n",
    "        self.samples   = samples\n",
    "\n",
    "    def attack(self, x_orig, tgt_label):\n",
    "        device = x_orig.device\n",
    "        delta  = torch.zeros_like(x_orig, device=device)\n",
    "        tgt    = torch.tensor([tgt_label], device=device)\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            grad_est = torch.zeros_like(delta)\n",
    "            for _ in range(self.samples):\n",
    "                u = torch.randint(0,2, x_orig.shape, device=device).float()*2 - 1\n",
    "                # two probe points\n",
    "                x_p = torch.clamp(x_orig + delta + self.sigma*u, self.lo, self.hi)\n",
    "                x_n = torch.clamp(x_orig + delta - self.sigma*u, self.lo, self.hi)\n",
    "\n",
    "                lp, _ = self.model(x_p)\n",
    "                ln, _ = self.model(x_n)\n",
    "                l_p = F.cross_entropy(lp, tgt)\n",
    "                l_n = F.cross_entropy(ln, tgt)\n",
    "\n",
    "                diff = (l_p - l_n) if self.targeted else (l_n - l_p)\n",
    "                grad_est += diff.view_as(delta) * u / (2*self.sigma)\n",
    "\n",
    "            grad_est /= self.samples\n",
    "            delta = delta - self.lr * grad_est\n",
    "            # keep within bounds\n",
    "            delta = torch.clamp(delta, self.lo - x_orig, self.hi - x_orig)\n",
    "\n",
    "        return torch.clamp(x_orig + delta, self.lo, self.hi).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9d0aba4-1d9b-4d0a-8988-ff5e81706504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='data', train=True,  download=True, transform=transform_train)\n",
    "testset  = torchvision.datasets.CIFAR10(root='data', train=False, download=True, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True,  num_workers=2)\n",
    "testloader  = torch.utils.data.DataLoader(testset,  batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64d08d0a-4dd4-40b0-89df-9ccc3f018564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model     = ResNet56().to(device)\n",
    "surrogate = model\n",
    "target    = copy.deepcopy(model)\n",
    "surrogate.eval()\n",
    "target.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "spsa = SPSAAttack(\n",
    "    model=target,\n",
    "    bounds=(0.0,1.0),\n",
    "    sigma=1e-3,\n",
    "    lr=1e-2,\n",
    "    max_iter=150,\n",
    "    targeted=True,\n",
    "    samples=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f981377-c495-4199-a874-2abe0b9b5143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity clean: 0.4564, adversarial: 0.4304\n"
     ]
    }
   ],
   "source": [
    "for imgs, _ in testloader:\n",
    "    imgs = imgs.to(device)\n",
    "\n",
    "    # (1) Clean predictions on target\n",
    "    with torch.no_grad():\n",
    "        logits_c, acts_c = target(quantize_input(imgs))\n",
    "        preds_c = logits_c.argmax(1)\n",
    "\n",
    "    # (2) Stage‑1: White‑box sparsity on surrogate\n",
    "    imgs_q = quantize_input(imgs)\n",
    "    imgs_s1 = generate_sparsity_adversary(\n",
    "                  surrogate, imgs_q, preds_c, criterion,\n",
    "                  epsilon=0.3, alpha=0.02, num_iter=60, c=0.0, beta=20.0\n",
    "              )\n",
    "\n",
    "    # (3) Stage‑2: Repair any flipped preds via SPSA\n",
    "    imgs_adv = imgs_s1.clone()\n",
    "    for i in range(imgs.size(0)):\n",
    "        with torch.no_grad():\n",
    "            pred_i = target(imgs_s1[i:i+1])[0].argmax(1)\n",
    "        if pred_i != preds_c[i]:\n",
    "            imgs_adv[i:i+1] = spsa.attack(imgs_s1[i:i+1], preds_c[i].item())\n",
    "\n",
    "    # (4) Measure sparsity change\n",
    "    with torch.no_grad():\n",
    "        _, acts_a = target(quantize_input(imgs_adv))\n",
    "\n",
    "    sp_c = sum((a!=0).float().sum() for a in acts_c) / sum(a.numel() for a in acts_c)\n",
    "    sp_a = sum((a!=0).float().sum() for a in acts_a) / sum(a.numel() for a in acts_a)\n",
    "    print(f\"Sparsity clean: {sp_c:.4f}, adversarial: {sp_a:.4f}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6309c148-cf95-4792-925f-9b6af61ebad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
